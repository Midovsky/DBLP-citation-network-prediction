{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document(object):\n",
    "    \n",
    "    def __init__(self,id, title, authors, venue, year, n_citation, references =[], abstract ='', *args, **kwargs ):\n",
    "        self.id = id\n",
    "        self.title = title\n",
    "        self.authors = authors\n",
    "        self.venue = venue\n",
    "        self.year = year\n",
    "        self.n_citation = n_citation\n",
    "        self.references = references\n",
    "        self.abstract = abstract\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.id)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.id)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/midovsky/anaconda3/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n",
      "/home/midovsky/anaconda3/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:676: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if cb.iterable(node_size):  # many node sizes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a top number: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le graph Ginf des 5 top noeuds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing networkx \n",
    "import networkx as nx \n",
    "\n",
    "import json \n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# importing matplotlib.pyplot \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from numpy import random\n",
    "\n",
    "# to display all outputs (not only the last one))\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# to center figure on display\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# function that return the \"nb\" top first elements\n",
    "def sort_top(pr,top_nb):\n",
    "    sorted_pr = sorted(pr.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    sorted_top =[]\n",
    "    for i in range(top_nb):\n",
    "        sorted_top.append(sorted_pr[i])\n",
    "        \n",
    "    return sorted_top\n",
    "\n",
    "# create an empty graph (DiGraph: directed graph)\n",
    "G = nx.DiGraph()\n",
    "\n",
    "\n",
    "# read input file\n",
    "data = [json.loads(line) for line in open('db_v10_example_modified_ids.json', 'r')]\n",
    "\n",
    "\n",
    "# browse the file, extract each object of type \"Document\" and assign it to a node\n",
    "for document in data:\n",
    "    \n",
    "    # Parse JSON into an object with attributes corresponding to dict keys.\n",
    "    \n",
    "    # With json.loads(document), I'm calling json.loads with a dictionary as input (which gives an error).\n",
    "\n",
    "    # I can fix it as follows:\n",
    "    \n",
    "    s1 = json.dumps(document)\n",
    "    \n",
    "    j= json.loads(s1)\n",
    "    \n",
    "    u = Document(**j)\n",
    "    \n",
    "    G.add_node(u)\n",
    "\n",
    "\n",
    "# add the links (edges between documents)\n",
    "for node in G:\n",
    "    if hasattr(node, 'references'):\n",
    "        for i in node.references:\n",
    "            for d in G:\n",
    "                if (i == (d.id)) and (d != node):\n",
    "                    G.add_edge(node,d)\n",
    "\n",
    "# specify figure size\n",
    "plt.figure(3,figsize=(8,6))                     \n",
    "nx.draw(G,node_size=500, with_labels=True)\n",
    "\n",
    "# apply page rank algorithm\n",
    "pr=nx.pagerank(G,0.4) \n",
    "pr\n",
    "\n",
    "# Declare Ginf graph\n",
    "Ginf = nx.DiGraph()\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "        nb = int(input('Enter a top number: '))\n",
    "        \n",
    "        #sort pr: returns the nb top pr\n",
    "        test = sort_top(pr,nb)\n",
    "\n",
    "        for i in range(nb):\n",
    "\n",
    "            # Create ego graph\n",
    "            # When unidirected=False : only successors of the nodes are drawn\n",
    "            # When unidirected=True : successors and predecessors of the nodes are drawn\n",
    "            hub_ego=nx.ego_graph(G,test[i][0],undirected=False)\n",
    "\n",
    "            \n",
    "            #Update Ginf graph\n",
    "            Ginf.update(hub_ego)\n",
    "            \n",
    "            # Draw graph ego\n",
    "            pos=nx.spring_layout(hub_ego)\n",
    "            nx.draw(hub_ego,pos,node_color='b',node_size=300,with_labels=True)\n",
    "\n",
    "            # Draw ego as large and red\n",
    "            nx.draw_networkx_nodes(hub_ego,pos,nodelist=[test[i][0]],node_size=300,node_color='r')\n",
    "            plt.show()\n",
    "            \n",
    "print('Le graph Ginf des ' + str(nb) +' top noeuds')\n",
    "nx.draw(Ginf,with_labels=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les titres réalisés par Makoto Satoh sont:\n",
      "['Preliminary Design of a Network Protocol Learning Tool Based on the Comprehension of High School Students: Design by an Empirical Study Using a Simple Mind Map']\n",
      "Les titres de ce Ginf sont:\n",
      "['Reasonig about Set-Oriented Methods in Object Databases.', 'Development of Remote Monitoring and Control Device for 50KW PV System Based on the Wireless Network', 'Preliminary Design of a Network Protocol Learning Tool Based on the Comprehension of High School Students: Design by an Empirical Study Using a Simple Mind Map', 'COMPARING GNG3D AND QUADRIC ERROR METRICS METHODS TO SIMPLIFY 3D MESHES', 'Comparison of GARCH, Neural Network and Support Vector Machine in Financial Time Series Prediction', 'A methodology for the physically accurate visualisation of roman polychrome statuary', 'Improved Secret Image Sharing Method By Encoding Shared Values With Authentication Bits', 'Towards Elastic Component-Based Cloud Applications', 'The expressive space of IDS-as-Art', 'Interactive Experience, Art and Evaluation', 'Second-kind integral formulations of the capacitance problem', 'Vectorial fast correlation attacks.']\n",
      "['Giovanna Guerrini', 'Isabella Merlo', 'Jea-Bum Park', 'Byungmok Kim', 'Jian Shen', 'Sun-Young Kim', 'Dae-Seok Rho', 'Makoto Satoh', 'Ryo Muramatsu', 'Mizue Kayama', 'Kazunori Itoh', 'Masami Hashimoto', 'Makoto Otani', 'Michio Shimizu', 'Masahiko Sugimoto', 'Rafael Álvarez', 'Leandro Tortosa', 'José-Francisco Vicent', 'Antonio Zamora', 'Altaf Hossain', 'Faisal Zaman', 'Mohammed Nasser', 'M. Mufakhkharul Islam', 'Gareth Beale', 'Graeme Earl', 'Guzin Ulutas', 'Mustafa Ulutas', 'Vasif V. Nabiyev', 'Alexander Pokahr', 'Lars Braubach', 'Noam Knoller', 'Linda Candy', 'Sam Ferguson', 'Johannes Tausch', 'Jacob K. White', 'Jovan Dj. Golic', 'Guglielmo Morgari']\n"
     ]
    }
   ],
   "source": [
    "# return titles by author\n",
    "def search_by_author(g,author):\n",
    "    titles=[]\n",
    "    for node in g:\n",
    "        if hasattr(node, 'authors') and author in node.authors and (not node.title in titles):\n",
    "            titles.append(node.title)\n",
    "    return titles\n",
    "\n",
    "# return all titles\n",
    "def search_titles(g):\n",
    "    titles=[]\n",
    "    for node in g:\n",
    "        if hasattr(node, 'title'):\n",
    "            if not node.title in titles:\n",
    "                titles.append(node.title)\n",
    "    return titles\n",
    "\n",
    "#return all authors\n",
    "def search_authors(g):\n",
    "    authors=[]\n",
    "    for node in g:\n",
    "        if hasattr(node, 'authors'):\n",
    "            for i in node.authors:\n",
    "                if not i in authors:\n",
    "                    authors.append(i)\n",
    "    return authors\n",
    "\n",
    "def search_venues(g):\n",
    "    venues=[]\n",
    "    for node in g:\n",
    "        if hasattr(node, 'venue'):\n",
    "            if not node.venue in venues:\n",
    "                venues.append(node.venue)\n",
    "    return venues\n",
    "\n",
    "#return all abstracts\n",
    "def search_abstracts(g):\n",
    "    abstracts=[]\n",
    "    for node in g:\n",
    "        if hasattr(node, 'abstract') and (not node.abstract in abstracts):\n",
    "            abstracts.append(node.abstract)\n",
    "    return abstracts\n",
    "\n",
    "titles = search_by_author(Ginf,\"Makoto Satoh\")\n",
    "print(\"Les titres réalisés par Makoto Satoh sont:\")\n",
    "print(titles)\n",
    "\n",
    "\n",
    "titles = search_titles(Ginf)\n",
    "print(\"Les titres de ce Ginf sont:\")\n",
    "print(titles)\n",
    "\n",
    "authors = search_authors(Ginf)\n",
    "print(authors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/midovsky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/midovsky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['purpos', 'studi', 'develop', 'learn', 'tool', 'high', 'school', 'student', 'studi', 'scientif', 'aspect', 'inform', 'communic', 'work', 'specif', 'focus', 'basic', 'principl', 'network', 'proto', 'col', 'develop', 'learn', 'tool', 'tool', 'give', 'student', 'hand', 'experi', 'help', 'understand', 'basic', 'principl', 'network', 'protocol'], ['articl', 'appli', 'garch', 'model', 'instead', 'arma', 'model', 'compar', 'standard', 'forecast', 'intern', 'includ', 'asian', 'stock', 'market', 'indic', 'model', 'evalu', 'perform', 'metric', 'criteria', 'experiment', 'result', 'show', 'superior', 'garch', 'model', 'compar', 'standard', 'forecast', 'intern', 'stock', 'market', 'indic'], ['paper', 'describ', 'design', 'implement', 'methodolog', 'visualis', 'hypothet', 'virtual', 'reconstruct', 'roman', 'polychrom', 'statuari', 'research', 'purpos', 'methodolog', 'intend', 'attempt', 'visualis', 'simpli', 'believ', 'physic', 'accur', 'approach', 'accur', 'represent', 'polychrom', 'statuari', 'great', 'potenti', 'util', 'mean', 'illustr', 'exist', 'interpret', 'mean', 'test', 'revis', 'develop', 'hypothes', 'goal', 'methodolog', 'propos', 'pipelin', 'incorpor', 'high', 'degre', 'physic', 'accuraci', 'whilst', 'practic', 'applic', 'convent', 'archaeolog', 'research', 'set', 'methodolog', 'design', 'allow', 'accur', 'visualis', 'surviv', 'object', 'colour', 'provid', 'reliabl', 'method', 'hypothet', 'reconstruct', 'element', 'longer', 'surviv', 'process', 'propos', 'intend', 'limit', 'need', 'specialist', 'record', 'equip', 'utilis', 'exist', 'data', 'data', 'collect', 'wide', 'avail', 'technolog', 'present', 'implement', 'statu', 'context', 'project', 'herculaneum', 'demonstr', 'case', 'studi', 'small', 'area', 'head', 'paint', 'femal', 'statu', 'discov', 'herculaneum']]\n",
      "0 aspect\n",
      "1 basic\n",
      "2 col\n",
      "3 communic\n",
      "4 develop\n",
      "5 experi\n",
      "6 focus\n",
      "7 give\n",
      "8 hand\n",
      "9 help\n",
      "10 high\n",
      "Word 0 (\"aspect\") appears 1 time.\n",
      "Word 1 (\"basic\") appears 2 time.\n",
      "Word 2 (\"col\") appears 1 time.\n",
      "Word 3 (\"communic\") appears 1 time.\n",
      "Word 4 (\"develop\") appears 2 time.\n",
      "Word 5 (\"experi\") appears 1 time.\n",
      "Word 6 (\"focus\") appears 1 time.\n",
      "Word 7 (\"give\") appears 1 time.\n",
      "Word 8 (\"hand\") appears 1 time.\n",
      "Word 9 (\"help\") appears 1 time.\n",
      "Word 10 (\"high\") appears 1 time.\n",
      "Word 11 (\"inform\") appears 1 time.\n",
      "Word 12 (\"learn\") appears 2 time.\n",
      "Word 13 (\"network\") appears 2 time.\n",
      "Word 14 (\"principl\") appears 2 time.\n",
      "Word 15 (\"proto\") appears 1 time.\n",
      "Word 16 (\"protocol\") appears 1 time.\n",
      "Word 17 (\"purpos\") appears 1 time.\n",
      "Word 18 (\"school\") appears 1 time.\n",
      "Word 19 (\"scientif\") appears 1 time.\n",
      "Word 20 (\"specif\") appears 1 time.\n",
      "Word 21 (\"student\") appears 2 time.\n",
      "Word 22 (\"studi\") appears 2 time.\n",
      "Word 23 (\"tool\") appears 3 time.\n",
      "Word 24 (\"understand\") appears 1 time.\n",
      "Word 25 (\"work\") appears 1 time.\n",
      "Word 26 (\"appli\") appears 1 time.\n",
      "Word 27 (\"arma\") appears 1 time.\n",
      "Word 28 (\"articl\") appears 1 time.\n",
      "Word 29 (\"asian\") appears 1 time.\n",
      "Word 30 (\"compar\") appears 2 time.\n",
      "Word 31 (\"criteria\") appears 1 time.\n",
      "Word 32 (\"evalu\") appears 1 time.\n",
      "Word 33 (\"experiment\") appears 1 time.\n",
      "Word 34 (\"forecast\") appears 2 time.\n",
      "Word 35 (\"garch\") appears 2 time.\n",
      "Word 36 (\"includ\") appears 1 time.\n",
      "Word 37 (\"indic\") appears 2 time.\n",
      "Word 38 (\"instead\") appears 1 time.\n",
      "Word 39 (\"intern\") appears 2 time.\n",
      "Word 40 (\"market\") appears 2 time.\n",
      "Word 41 (\"metric\") appears 1 time.\n",
      "Word 42 (\"model\") appears 4 time.\n",
      "Word 43 (\"perform\") appears 1 time.\n",
      "Word 44 (\"result\") appears 1 time.\n",
      "Word 45 (\"show\") appears 1 time.\n",
      "Word 46 (\"standard\") appears 2 time.\n",
      "Word 47 (\"stock\") appears 2 time.\n",
      "Word 48 (\"superior\") appears 1 time.\n",
      "Word 4 (\"develop\") appears 1 time.\n",
      "Word 10 (\"high\") appears 1 time.\n",
      "Word 17 (\"purpos\") appears 1 time.\n",
      "Word 22 (\"studi\") appears 1 time.\n",
      "Word 49 (\"accur\") appears 3 time.\n",
      "Word 50 (\"accuraci\") appears 1 time.\n",
      "Word 51 (\"allow\") appears 1 time.\n",
      "Word 52 (\"applic\") appears 1 time.\n",
      "Word 53 (\"approach\") appears 1 time.\n",
      "Word 54 (\"archaeolog\") appears 1 time.\n",
      "Word 55 (\"area\") appears 1 time.\n",
      "Word 56 (\"attempt\") appears 1 time.\n",
      "Word 57 (\"avail\") appears 1 time.\n",
      "Word 58 (\"believ\") appears 1 time.\n",
      "Word 59 (\"case\") appears 1 time.\n",
      "Word 60 (\"collect\") appears 1 time.\n",
      "Word 61 (\"colour\") appears 1 time.\n",
      "Word 62 (\"context\") appears 1 time.\n",
      "Word 63 (\"convent\") appears 1 time.\n",
      "Word 64 (\"data\") appears 2 time.\n",
      "Word 65 (\"degre\") appears 1 time.\n",
      "Word 66 (\"demonstr\") appears 1 time.\n",
      "Word 67 (\"describ\") appears 1 time.\n",
      "Word 68 (\"design\") appears 2 time.\n",
      "Word 69 (\"discov\") appears 1 time.\n",
      "Word 70 (\"element\") appears 1 time.\n",
      "Word 71 (\"equip\") appears 1 time.\n",
      "Word 72 (\"exist\") appears 2 time.\n",
      "Word 73 (\"femal\") appears 1 time.\n",
      "Word 74 (\"goal\") appears 1 time.\n",
      "Word 75 (\"great\") appears 1 time.\n",
      "Word 76 (\"head\") appears 1 time.\n",
      "Word 77 (\"herculaneum\") appears 2 time.\n",
      "Word 78 (\"hypothes\") appears 1 time.\n",
      "Word 79 (\"hypothet\") appears 2 time.\n",
      "Word 80 (\"illustr\") appears 1 time.\n",
      "Word 81 (\"implement\") appears 2 time.\n",
      "Word 82 (\"incorpor\") appears 1 time.\n",
      "Word 83 (\"intend\") appears 2 time.\n",
      "Word 84 (\"interpret\") appears 1 time.\n",
      "Word 85 (\"limit\") appears 1 time.\n",
      "Word 86 (\"longer\") appears 1 time.\n",
      "Word 87 (\"mean\") appears 2 time.\n",
      "Word 88 (\"method\") appears 1 time.\n",
      "Word 89 (\"methodolog\") appears 4 time.\n",
      "Word 90 (\"need\") appears 1 time.\n",
      "Word 91 (\"object\") appears 1 time.\n",
      "Word 92 (\"paint\") appears 1 time.\n",
      "Word 93 (\"paper\") appears 1 time.\n",
      "Word 94 (\"physic\") appears 2 time.\n",
      "Word 95 (\"pipelin\") appears 1 time.\n",
      "Word 96 (\"polychrom\") appears 2 time.\n",
      "Word 97 (\"potenti\") appears 1 time.\n",
      "Word 98 (\"practic\") appears 1 time.\n",
      "Word 99 (\"present\") appears 1 time.\n",
      "Word 100 (\"process\") appears 1 time.\n",
      "Word 101 (\"project\") appears 1 time.\n",
      "Word 102 (\"propos\") appears 2 time.\n",
      "Word 103 (\"provid\") appears 1 time.\n",
      "Word 104 (\"reconstruct\") appears 2 time.\n",
      "Word 105 (\"record\") appears 1 time.\n",
      "Word 106 (\"reliabl\") appears 1 time.\n",
      "Word 107 (\"represent\") appears 1 time.\n",
      "Word 108 (\"research\") appears 2 time.\n",
      "Word 109 (\"revis\") appears 1 time.\n",
      "Word 110 (\"roman\") appears 1 time.\n",
      "Word 111 (\"set\") appears 1 time.\n",
      "Word 112 (\"simpli\") appears 1 time.\n",
      "Word 113 (\"small\") appears 1 time.\n",
      "Word 114 (\"specialist\") appears 1 time.\n",
      "Word 115 (\"statu\") appears 2 time.\n",
      "Word 116 (\"statuari\") appears 2 time.\n",
      "Word 117 (\"surviv\") appears 2 time.\n",
      "Word 118 (\"technolog\") appears 1 time.\n",
      "Word 119 (\"test\") appears 1 time.\n",
      "Word 120 (\"util\") appears 1 time.\n",
      "Word 121 (\"utilis\") appears 1 time.\n",
      "Word 122 (\"virtual\") appears 1 time.\n",
      "Word 123 (\"visualis\") appears 3 time.\n",
      "Word 124 (\"whilst\") appears 1 time.\n",
      "Word 125 (\"wide\") appears 1 time.\n",
      "Word 0 (\"aspect\") appears 2 time.\n",
      "Word 4 (\"develop\") appears 1 time.\n",
      "Word 36 (\"includ\") appears 1 time.\n",
      "Word 43 (\"perform\") appears 2 time.\n",
      "Word 53 (\"approach\") appears 3 time.\n",
      "Word 68 (\"design\") appears 2 time.\n",
      "Word 85 (\"limit\") appears 1 time.\n",
      "Word 87 (\"mean\") appears 1 time.\n",
      "Word 108 (\"research\") appears 1 time.\n",
      "Word 126 (\"abil\") appears 1 time.\n",
      "Word 127 (\"accord\") appears 1 time.\n",
      "Word 128 (\"agenc\") appears 2 time.\n",
      "Word 129 (\"altern\") appears 1 time.\n",
      "Word 130 (\"appeal\") appears 1 time.\n",
      "Word 131 (\"argu\") appears 1 time.\n",
      "Word 132 (\"artist\") appears 1 time.\n",
      "Word 133 (\"author\") appears 1 time.\n",
      "Word 134 (\"central\") appears 1 time.\n",
      "Word 135 (\"communiti\") appears 1 time.\n",
      "Word 136 (\"complex\") appears 1 time.\n",
      "Word 137 (\"conting\") appears 1 time.\n",
      "Word 138 (\"creation\") appears 1 time.\n",
      "Word 139 (\"desir\") appears 1 time.\n",
      "Word 140 (\"dynam\") appears 1 time.\n",
      "Word 141 (\"effort\") appears 1 time.\n",
      "Word 142 (\"expect\") appears 1 time.\n",
      "Word 143 (\"explor\") appears 1 time.\n",
      "Word 144 (\"express\") appears 1 time.\n",
      "Word 145 (\"formal\") appears 1 time.\n",
      "Word 146 (\"guid\") appears 1 time.\n",
      "Word 147 (\"highlight\") appears 1 time.\n",
      "Word 148 (\"implic\") appears 1 time.\n",
      "Word 149 (\"manipul\") appears 1 time.\n",
      "Word 150 (\"matter\") appears 1 time.\n",
      "Word 151 (\"offer\") appears 2 time.\n",
      "Word 152 (\"open\") appears 1 time.\n",
      "Word 153 (\"opportun\") appears 1 time.\n",
      "Word 154 (\"paramet\") appears 1 time.\n",
      "Word 155 (\"place\") appears 1 time.\n",
      "Word 156 (\"possibl\") appears 1 time.\n",
      "Word 157 (\"probabl\") appears 1 time.\n",
      "Word 158 (\"reflect\") appears 1 time.\n",
      "Word 159 (\"signific\") appears 1 time.\n",
      "Word 160 (\"space\") appears 1 time.\n",
      "Word 161 (\"storyworld\") appears 2 time.\n",
      "Word 162 (\"subintent\") appears 1 time.\n",
      "Word 163 (\"subject\") appears 1 time.\n",
      "Word 164 (\"unnecessari\") appears 1 time.\n",
      "Word 165 (\"user\") appears 4 time.\n",
      "Word 166 (\"valid\") appears 1 time.\n",
      "Word 167 (\"vast\") appears 1 time.\n",
      "Word 5 (\"experi\") appears 1 time.\n",
      "Word 46 (\"standard\") appears 1 time.\n",
      "Word 50 (\"accuraci\") appears 1 time.\n",
      "Word 53 (\"approach\") appears 2 time.\n",
      "Word 66 (\"demonstr\") appears 1 time.\n",
      "Word 67 (\"describ\") appears 1 time.\n",
      "Word 93 (\"paper\") appears 1 time.\n",
      "Word 168 (\"acceler\") appears 1 time.\n",
      "Word 169 (\"calcul\") appears 1 time.\n",
      "Word 170 (\"capacit\") appears 1 time.\n",
      "Word 171 (\"charg\") appears 1 time.\n",
      "Word 172 (\"condit\") appears 1 time.\n",
      "Word 173 (\"densiti\") appears 2 time.\n",
      "Word 174 (\"differ\") appears 1 time.\n",
      "Word 175 (\"dipol\") appears 1 time.\n",
      "Word 176 (\"direct\") appears 1 time.\n",
      "Word 177 (\"discret\") appears 2 time.\n",
      "Word 178 (\"effici\") appears 1 time.\n",
      "Word 179 (\"electrostat\") appears 2 time.\n",
      "Word 180 (\"equat\") appears 3 time.\n",
      "Word 181 (\"forc\") appears 2 time.\n",
      "Word 182 (\"formul\") appears 1 time.\n",
      "Word 183 (\"integr\") appears 3 time.\n",
      "Word 184 (\"investig\") appears 1 time.\n",
      "Word 185 (\"involv\") appears 1 time.\n",
      "Word 186 (\"kind\") appears 3 time.\n",
      "Word 187 (\"lead\") appears 1 time.\n",
      "Word 188 (\"linear\") appears 1 time.\n",
      "Word 189 (\"matrix\") appears 1 time.\n",
      "Word 190 (\"monopol\") appears 1 time.\n",
      "Word 191 (\"multipl\") appears 1 time.\n",
      "Word 192 (\"multipol\") appears 1 time.\n",
      "Word 193 (\"numer\") appears 1 time.\n",
      "Word 194 (\"problem\") appears 1 time.\n",
      "Word 195 (\"relat\") appears 1 time.\n",
      "Word 196 (\"scheme\") appears 1 time.\n",
      "Word 197 (\"second\") appears 2 time.\n",
      "Word 198 (\"solv\") appears 2 time.\n",
      "Word 199 (\"surfac\") appears 1 time.\n",
      "Word 200 (\"system\") appears 1 time.\n",
      "Word 201 (\"usual\") appears 1 time.\n",
      "Word 202 (\"vector\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# initializing stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "abstracts = search_abstracts(Ginf)\n",
    "\n",
    "# convert abstracts into dict with one key in order to apply lda algorithm\n",
    "# the key here is: \"abstract\"\n",
    "documents = {\"abstracts\": abstracts[0:]}\n",
    "\n",
    "# Certain parts of English speech, like conjunctions (“for”, “or”) or the word “the” are meaningless to a topic model.\n",
    "# These terms are called stop words and need to be removed from our token list.\n",
    "# function that lematizes and stemms\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenization segments a document into its atomic elements. (into words)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "processed_docs = list(map(preprocess,documents['abstracts']))\n",
    "\n",
    "# print the first 4 preprocessed elements\n",
    "print(processed_docs[:4])\n",
    "\n",
    "# Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "\n",
    "#Filter out tokens\n",
    "dictionary.filter_extremes(no_below=0)\n",
    "\n",
    "#transform our dict into a bag of words\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# display occurence of words in every document\n",
    "for doc in bow_corpus:\n",
    "    for i in range(len(doc)):\n",
    "        print(\"Word {} (\\\"{}\\\") appears {} time.\".format(doc[i][0], \n",
    "                                               dictionary[doc[i][0]],doc[i][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.005*\"model\" + 0.005*\"methodolog\" + 0.005*\"standard\" + 0.005*\"develop\" + 0.005*\"studi\"\n",
      "Topic: 1 \n",
      "Words: 0.027*\"methodolog\" + 0.021*\"accur\" + 0.021*\"visualis\" + 0.015*\"research\" + 0.015*\"mean\"\n",
      "Topic: 2 \n",
      "Words: 0.029*\"user\" + 0.029*\"model\" + 0.022*\"approach\" + 0.022*\"perform\" + 0.015*\"aspect\"\n",
      "Topic: 3 \n",
      "Words: 0.023*\"tool\" + 0.023*\"kind\" + 0.023*\"integr\" + 0.023*\"equat\" + 0.016*\"develop\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.97906506)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply lda model\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=4, id2word=dictionary, passes=20)\n",
    "\n",
    "# num_words: number of relevant words in every topic\n",
    "for idx, topic in lda_model.print_topics(num_words=5): #or -1 as parameter\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    \n",
    "# To print the % of topics a document is about, do the following:\n",
    "lda_model[bow_corpus[1]] # bow_corpus[0] means the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.25), (1, 0.25), (2, 0.25), (3, 0.25)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.97906506)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.97853625)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0.9928141)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.9880239)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.9865438)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to display the topics of all documents\n",
    "for doc in bow_corpus:\n",
    "    lda_model[doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, '0.029*\"user\" + 0.029*\"model\" + 0.022*\"approach\"'), (0, '0.005*\"model\" + 0.005*\"methodolog\" + 0.005*\"standard\"'), (3, '0.023*\"tool\" + 0.023*\"kind\" + 0.023*\"integr\"')]\n"
     ]
    }
   ],
   "source": [
    "# print the topic number + percentage\n",
    "print(lda_model.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9790648221969604\t \n",
      "Topic: 0.023*\"tool\" + 0.023*\"kind\" + 0.023*\"integr\" + 0.023*\"equat\" + 0.016*\"develop\" + 0.016*\"studi\" + 0.016*\"principl\" + 0.016*\"student\" + 0.016*\"learn\" + 0.016*\"discret\"\n"
     ]
    }
   ],
   "source": [
    "# to check where a document can be classified\n",
    "for index, score in sorted(lda_model[bow_corpus[1]], key=lambda tup: -1*tup[1]): # exemple doc num 1\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
